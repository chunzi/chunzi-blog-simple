脏词过滤

公司里接到网监处的通知，对于使用我们公司提供的网站，必须要有文字过滤，避免那些敏感的上不了台面的词汇出现在各种网站上。

我是不同意这种做法的。堵而不疏，连标都治不了。不过既然上头有命令，还是老老实实做一下吧。不想搞得太复杂，只要基本上可以用就行。

思路很简单，先设置脏词列表，然后从指定的目录开始，遇到子目录进去递归，遇到文件并且是文本文件就打开，逐个关键词匹配，找到的话打印清单。用到两个模块，一个 Path::Class 用来处理文件和目录的，一个 File::Slurp，用来直接读入文件内容和输出报告。

做了一次测试，查出来好多都是新闻中提到或者垃圾回复的情况。所以以后如果要扩展的话，还要加上数据库保存检查结果，并通过人工判定，再行处理。此外目前也只是按照  GB2312  来匹配，应该还需要 UTF-8，Big5 等。还有种方式就是在  Apache  中增加一个过滤的 module，实现起来应该不复杂，不过觉着没什么必要，先应付了检查再说。