代码进化

我现在的工作内容之一是写 Anti-Spam 规则，规则保存在若干 .cf 文件中，每个规则都必须有个唯一的名称。发 Spam 的人知道你会写规则，所以有些关键的地方，他们都会尝试多种变形以逃过滤网。而取规则名的时候按意思或者元信息，所以不经意间就会出现规则名重复。尽管不多，但总不好。

四天前，我写了一个 one-liner :
<pre>less *.cf | awk ' $0 !~ /^#/ &amp;&amp; $0 !="" {print $2}' | sort | uniq -c | sort -nr | awk ' $1 &gt; 1 {print}'</pre>
less 读取当前目录下的规则文件，然后给 awk，找到不是注释的行，也不是空行的那些，打印第 2 列，也就是规则名，然后排序，再用 uniq 计数把重复次数追加在行首，然后再用 sort 按照数字倒序排列，最后取出数字大于 1 的，也就是有重复的那些规则名打应出来，包括重复计数。

这两天翻过《BSD HACKER》 之后，就觉得这个好罗嗦，于是重写：
<pre>sed '/^#/d;/^$/d' *.cf | awk '{ print $2 }' | sort | uniq -dc</pre>
直接用 sed 读规则文件，将注释行删除，将空行删除，然后给 awk 打印规则名，给 sort 排序，然后让 uniq 只输出重复的行并计数。

怎么说呢，这就是知道什么不知道什么的差别。开始我愚蠢的用 less 传文件内容，这是思维定势，自己总用 less 看文件，就觉得程序也该用 less 看文件。uniq 的 -d 参数一下子把最后一段罗嗦的 awk 代码斩掉。原先用 awk 的模式来找规则行，不如 sed 的两个替换干脆明快，两个 d 命令让我觉得很爽。